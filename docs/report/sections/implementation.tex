\section{Implementation}
\subsection{Architecture}
\subsection{User Interface}
\subsection{Database Design}
\subsubsection{PostgreSQL}

PostgreSQL was used for this project because of its high scability and stability.
Complex queries are performed faster in PostgreSQL than alternatives such as MySQL
which is important for optimising our search times especially for a large property
dataset. PostgreSQL is also ACID (Atomicity, Consistency, Isolation, Durability)
compliant, which ensures that no data is lost in the system in the case of failures.
Since we receive a large number of database read and writes towards the end
of an auction session, concurrency control is vital to ensure the consistency
of data. PostgreSQL efficiently handles concurrency with its MVCC (Multiversion
Concurrency Control). Each database query sees only a snapshot of the database
when it was accessed, preventing the query from seeing inconsistent data that
could be caused by other concurrent updates on the same data. PostgreSQL is also
horizontally scalable as it supports data replication and sharding.
This is important if our project was to be extended and deployed outside the NSW
region and potentially globally.

\subsubsection{Database of localhost}

A full entity relationship diagram of our database can be found in Appendix.
The database of \emph{localhost} is normalised in 3NF (third normal form) as it
contains no transitive dependencies, minimising our data redundancy and
improving data integrity. Extensibility was kept in mind when designing the
database schema.

\subsubsection{Search Time Optimisation}

Property locations are determined by their latitude and longitude stored in the
database. When a user searches a location, the Google Maps API converts the location
into a latitude and longitude which is then used as the target destination.
The results of our property search are shown in order of closest distance to the
target destination.
Distance calculation is performed using Haversine's formula, which determines the
great-circle distance between two points in NSW. Vincenty's formula is a popular and
more accurate alternative for calculating distance, however we chose to
use Haversine's formula as it is computationally much faster.

\begin{lstlisting}[caption={Haversine's Formula}]
radlat = Radians(latitude)                      # Destination Lat
radlong = Radians(longitude)                    # Destination Long
radflat = Radians(models.F('latitude'))	        # Property Lat
radflong = Radians(models.F('longitude'))       # Property Long

distance = 6371 * Acos(
    Cos(radlat) * Cos(radflat) * Cos(radflong - radlong) +
    Sin(radlat) * Sin(radflat))
\end{lstlisting}

Our search query calculates the distance from each property to the target
destination using Haversine's Formula and then orders them by closest distance.
Since it is costly to calculate this for every property in the database, an
initial filter was added to narrow the number of properties that the
distance calculation had to be operated on.

\begin{lstlisting}[caption={Initial filter to narrow search results}]
lat_offset, lng_offset = Decimal(0.15), Decimal(0.15)
lat_range = (lat - lat_offset, lat + lat_offset)
lng_range = (lng - lng_offset, lng + lng_offset)
properties = Property.objects.within(lat, lng).filter(
    latitude__range=lat_range, longitude__range=lng_range)
\end{lstlisting}

Only properties within $\pm$0.15 latitude and longitude offsets of the original
search, which translates to around 15km, are shown. This greatly improves the
search times as well as removes properties that were outside a reasonable distance
from the search. By adding the initial filter, our search time is also no longer
restricted by the property dataset and is instead limited by suburb density.


\subsection{Real Time Communication}
\subsection{Event Scheduling}
When an auction session ends, tasks need to be performed in order to complete
the bidding process. There are also several places where scheduled/delayed tasks
are needed in the application.

Property items are said to be ``available'' if the \emph{available} option is
turned on by user (it is ``on'' by default when created) and there are no bids
in all the previous auction sessions in the same day. When the local time
reaches the end time of the session, the system have to check whether there are
bids in the session and create a booking for the winner. Property items that has
been booked out has to be marked as ``unavailable'' so that it does not come up
in the search results. Furthermore, property item has to be re-listed (marked
as ``available'') at 12 noon every day.

\subsubsection{Django Signals}
Signals are dispatched in Django when a certain action is performed within the
framework. It helps decoupled applications to get notified when the actions are
taken placed~\cite{django-signals}. Django provides a set of built-in signals
that allows us to combine it with Celery to perform certain tasks when signals
are dispatched. A list of signals we used in the project are:

\begin{itemize}
  \item \texttt{django.db.models.signals.m2m\_changed}
  \item \texttt{django.db.models.signals.pre\_save}
\end{itemize}

\subsubsection{Celery Beat}
Celery beat is a scheduler in Celery that kicks off tasks at regular intervals,
that are then executed by available worker nodes in the cluster~\cite{celery-beat}.
The worker works asynchronously to start task execution and store results in
a Redis instance.

By default, beat uses \texttt{PersistentScheduler} that keeps track of the last
run in a local shelve\footnote{a persistent, dictionary-like object} database
file. But that is not necessary since we already have a PostgreSQL database
active in the backend. So we instead use an extension
django-celery-beat~\ref{sec:dep-celery-beat} that allows us to store tasks in
the Django database through a \texttt{DatabaseScheduler}. The extension also
provides an admin interface so that tasks could be managed by the administrator.

\paragraph{Periodic Task}
\texttt{PeriodicTask} is a Django model provided by
django-celery-beat~\ref{sec:dep-celery-beat} that simulates how Celery tasks are
represented in the database. We use this in conjunction with
\texttt{DatabaseScheduler} to provide background services in the Django
framework.

\subsubsection{Combining both signals and Celery beat}
There are two tasks to be completed in the background:
\begin{enumerate}
  \item check if anyone bid on a property item; if there is, a booking is added
    to the winner's account, and bids associated with the property item are
    removed. Property item is marked as ``unavailable'' as well. Otherwise we do
    nothing about that property item.
  \item enable bidding for all property items at 12 noon
\end{enumerate}
As such, we define two tasks in Celery accordingly: \texttt{cleanup\_bids} and
\texttt{enable\_bids}. Whenever an auction session is added to a property item
(\texttt{m2m\_changed}), we add a \texttt{PeriodicTask} to the database that
executes \texttt{cleanup\_bids}. A \texttt{PeriodicTask} that executes
\texttt{enable\_bids} is added when a property item is
saved (\texttt{pre\_save}). When celery is launched, the scheduler will pick up
the tasks and triggers tasks execution when time reaches.
